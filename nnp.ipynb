{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ase.neighborlist import neighbor_list as make_neighbor_list\n",
    "import numpy as np\n",
    "from ase import Atoms\n",
    "from tqdm import trange, tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_cut_s_function(\n",
    "    r_ij_norm:torch.tensor,\n",
    "    r_cutoff:float\n",
    ")->torch.tensor:\n",
    "    \"\"\"DeepPot-SE\"\"\"\n",
    "    r_cutoff_smth=0.1\n",
    "    s_vec=torch.zeros_like(r_ij_norm)\n",
    "    flag=(r_ij_norm<=r_cutoff)\n",
    "\n",
    "    u=(r_ij_norm[flag]-r_cutoff_smth)/(r_cutoff-r_cutoff_smth)\n",
    "    s_vec[flag]=(u*u*u(-6*u*u+15*u-10)+1)/r_ij_norm[flag]\n",
    "\n",
    "    return s_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerPerceptron(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,activation_function):\n",
    "        super(ThreeLayerPerceptron,self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,hidden_size)\n",
    "        self.fc2=nn.Linear(hidden_size,hidden_size)\n",
    "        self.fc3=nn.Linear(hidden_size,output_size)\n",
    "        self.activation_function=activation_function\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.activation_function(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.activation_function(x)\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_to_relative_coords(\n",
    "    self,\n",
    "    coords:torch.tensor,\n",
    "    atom_i_idxs:torch.tensor,\n",
    "    atom_j_idxs:torch.tensor,\n",
    "    shift:torch.tensor\n",
    "):\n",
    "    coords_concat=torch.concat((\n",
    "        coords,\n",
    "        torch.full((1,3),1e5)\n",
    "    ),dim=0)\n",
    "    relative_coords=coords_concat[atom_j_idxs]-coords_concat[atom_i_idxs]+shift\n",
    "\n",
    "    return relative_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_cut_s_function(\n",
    "    r_ij_norm:torch.tensor, \n",
    "    r_cutoff:float, \n",
    ")->torch.tensor:\n",
    "    \"\"\"DeepPot-SE function s(r_ij) of tensor version\n",
    "    As r_ij becomes larger than r_cutoff_smth, the output of the function begins to decrease, \n",
    "    and as more r_ij becomes larger, the output of the function smoothly becomes zero.\n",
    "    Parameters\n",
    "    ----------\n",
    "        r_ij_norm : torch.tensor  \n",
    "            shape : (Coordination Num of atom i,)\n",
    "        r_cutoff : float\n",
    "            cutoff\n",
    "    Returns\n",
    "    -------\n",
    "        s_vec : torch.tensor\n",
    "            shape : (Coordination Num of atom i,)\n",
    "    \"\"\"\n",
    "    r_cutoff_smth = 0.1\n",
    "\n",
    "    s_vec = torch.zeros_like(r_ij_norm)\n",
    "    \n",
    "    flag = (r_ij_norm <= r_cutoff)\n",
    "\n",
    "    u = (r_ij_norm[flag] - r_cutoff_smth) / (r_cutoff - r_cutoff_smth)\n",
    "    s_vec[flag] =  (u*u*u*(-6*u*u + 15*u - 10) + 1) / (r_ij_norm[flag])\n",
    "\n",
    "    return s_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Natoms=4\n",
    "# coords=torch.arange(Natoms*3).reshape(Natoms,3)\n",
    "coords=torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]],dtype=torch.float)\n",
    "pprint(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 2.0000e+00, 3.0000e+00],\n",
       "        [4.0000e+00, 5.0000e+00, 6.0000e+00],\n",
       "        [1.0000e+05, 1.0000e+05, 1.0000e+05]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_concat=torch.concat((coords,torch.full((1,3),1e5)),dim=0)\n",
    "coords_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13., 13., 13.],\n",
       "        [13., 13., 13.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Natoms=2\n",
    "sel=1\n",
    "shift=10.0*torch.ones(Natoms*sel*3).reshape(Natoms*sel,3)\n",
    "relative_coords=coords_concat[1]-coords_concat[0]+shift\n",
    "relative_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0770, 0.0000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(s_vec)\n\u001b[1;32m      8\u001b[0m generalized_coords[:,\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m=\u001b[39mrelative_coords\n\u001b[0;32m----> 9\u001b[0m generalized_coords[:,\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m=\u001b[39m\u001b[43mgeneralized_coords\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ms_vec\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(relative_coords*s_vec.view(-1,1))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m generalized_coords\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "relative_coords=torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "generalized_coords=torch.full((relative_coords.shape[0],4),1e+2)\n",
    "r_ij_norm=torch.linalg.norm(relative_coords,dim=1)\n",
    "# r_cutoff=6.0\n",
    "s_vec=smooth_cut_s_function(r_ij_norm,r_cutoff)\n",
    "generalized_coords[:,0]=s_vec\n",
    "generalized_coords[:,1:]=relative_coords\n",
    "generalized_coords[:,1:]=generalized_coords[:,1:]*s_vec\n",
    "# print(relative_coords*s_vec.view(-1,1))\n",
    "generalized_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# view(-1,2)で最後のdimのsizeを2に, 他のdimは潰す:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 3))\n",
    "b = a.view(-1, 2) # 最後のdimのsizeを2に, 他のdimは\"潰す\"\n",
    "print(\"# view(-1,2)で最後のdimのsizeを2に, 他のdimは潰す:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPotSEModel(nn.Module):\n",
    "    def __init__(self,\n",
    "        max_atom_type:int,\n",
    "        atom_type_embed_nchanl:int,\n",
    "        m1:int,\n",
    "        m2:int,\n",
    "        fitting_hidden_size:int,\n",
    "        r_cutoff:float,\n",
    "        activation_function,\n",
    "        sel:int\n",
    "    ):\n",
    "        super(DeepPotSEModel,self).__init__()\n",
    "\n",
    "        self.r_cutoff=r_cutoff\n",
    "        self.max_atom_type=max_atom_type\n",
    "        self.m1=m1\n",
    "        self.m2=m2\n",
    "        self.activation_function=activation_function\n",
    "        self.sel=sel\n",
    "        self.atom_type_embed_nchanl=atom_type_embed_nchanl\n",
    "\n",
    "        self.atom_type_embed_net=ThreeLayerPerceptron(\n",
    "            input_size=max_atom_type+1,\n",
    "            hidden_size=atom_type_embed_nchanl,\n",
    "            output_size=atom_type_embed_nchanl,\n",
    "            activation_function=activation_function\n",
    "        )\n",
    "\n",
    "        self.embed_net=ThreeLayerPerceptron(\n",
    "            input_size=1+2*atom_type_embed_nchanl,\n",
    "            hidden_size=m1,\n",
    "            output_size=m1,\n",
    "            activation_function=activation_function\n",
    "        )\n",
    "\n",
    "        self.fitting_net=ThreeLayerPerceptron(\n",
    "            input_size=m1*m2+atom_type_embed_nchanl,\n",
    "            hidden_size=fitting_hidden_size,\n",
    "            output_size=1,\n",
    "            activation_function=activation_function\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "        coords:torch.tensor,\n",
    "        atom_types:torch.tensor,\n",
    "        atom_i_types:torch.tensor,\n",
    "        atom_j_types:torch.tensor,\n",
    "        atom_i_idxs:torch.tensor,\n",
    "        atom_j_idxs:torch.tensor,\n",
    "        shift:torch.tensor\n",
    "    ):\n",
    "        coords.requires_grad_(True)\n",
    "        relative_coords=self.coords_to_relative_coords(\n",
    "            coords=coords,\n",
    "            atom_i_idxs=atom_i_idxs,\n",
    "            atom_j_idxs=atom_j_idxs,\n",
    "            shift=shift\n",
    "        )\n",
    "\n",
    "        generalized_coords=self.relative_coords_to_generalized_coords(\n",
    "            relative_coords=relative_coords,\n",
    "            r_cutoff=self.r_cutoff\n",
    "        )\n",
    "\n",
    "        atom_type_one_hot=torch.eye(self.max_atom_type+1)\n",
    "        atom_type_embed_matrix=self.atom_type_embed_net(atom_type_one_hot)\n",
    "        total_potential_energy=torch.tensor(0.0)\n",
    "\n",
    "        s_rij=generalized_coords[:,0].reshape(-1,1)\n",
    "        atom_i_embeded_matrix=atom_type_embed_matrix[atom_i_types]\n",
    "        atom_j_embeded_matrix=atom_type_embed_matrix[atom_j_types]\n",
    "\n",
    "        gi1s_before_embed=torch.concat((\n",
    "            s_rij,\n",
    "            atom_i_embeded_matrix,\n",
    "            atom_j_embeded_matrix,\n",
    "        ),dim=1)\n",
    "\n",
    "        g_i1s=self.embed_net(gi1s_before_embed).reshape(coords.shape[0],self.sel,self.m1)\n",
    "        generalized_coords=generalized_coords.reshape(coords.shape[0],self.sel,4)\n",
    "\n",
    "        left=torch.bmm(\n",
    "            torch.transpose(gi1s,1,2),\n",
    "            generalized_coords\n",
    "        )\n",
    "\n",
    "        right=torch.bmm(\n",
    "            torch.transpose(generalized_coords,1,2),\n",
    "            g_i1s[:,:,:self.m2]\n",
    "        )\n",
    "\n",
    "        D_i_s_reshaped=torch.bmm(left,right).reshape(coords.shape[0],self.m1*self.m2)\n",
    "\n",
    "        feature_vectors=torch.concat((\n",
    "            D_i_s_reshaped,\n",
    "            atom_type_embed_matrix[atom_types]\n",
    "        ),dim=1)\n",
    "\n",
    "        total_potential_energy=torch.sum(\n",
    "            self.fitting_net(feature_vectors)\n",
    "        )\n",
    "\n",
    "        return total_potential_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
